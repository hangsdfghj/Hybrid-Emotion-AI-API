import os
import numpy as np
import jieba
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from google import genai
from google.genai import types
from flask import Flask, request, jsonify

# --- 0. å…¨å±€è®Šæ•¸èˆ‡æ¨¡å‹è¼‰å…¥ (åƒ…åœ¨æœå‹™å•Ÿå‹•æ™‚åŸ·è¡Œä¸€æ¬¡) ---

# ğŸš¨ å®‰å…¨æé†’ï¼šå¯¦éš›éƒ¨ç½²æ™‚ï¼Œè«‹ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ–å¯†é‘°ç®¡ç†æœå‹™ã€‚
# os.environ['GEMINI_API_KEY'] = 'AIzaSyA-YzMyQt_BIccMVqnt9t2IjoWq12P5rbQ'
client = genai.Client()

emotion_classes = np.array(['å­æƒ¡', 'å–œæ‚…', 'å¹³éœ', 'æ‚²å‚·', 'æ†¤æ€’', 'æœŸå¾…', 'ç„¦æ…®', 'é©šè¨']) 
max_len = 16 

# è¼‰å…¥ä½ è¨“ç·´å¥½çš„æ¨¡å‹
try:
    final_model = load_model('emotion_model.h5')
    print("æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚")
except Exception as e:
    print(f"éŒ¯èª¤ï¼šç„¡æ³•è¼‰å…¥ emotion_model.h5ã€‚è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
    # æœå‹™å•Ÿå‹•å¤±æ•—ï¼Œæ‡‰åœæ­¢

# ğŸŒŸ ã€é‡è¦æ­¥é©Ÿï¼šè¼‰å…¥æˆ–é‡å»º Tokenizerã€‘ğŸŒŸ
# ç”±æ–¼ tokenizer è®Šæ•¸ä¸æœƒè¢«ä¿å­˜åœ¨ .h5 æª”æ¡ˆä¸­ï¼Œä½ å¿…é ˆåœ¨é€™è£¡é‡æ–°å®šç¾©æˆ–è¼‰å…¥å®ƒï¼
# æœ€ç°¡å–®çš„æ–¹æ³•æ˜¯å¾ä½ çš„ CSV æ•¸æ“šä¸­é‡å»ºå®ƒï¼Œåƒä½ ä¹‹å‰åœ¨ Notebook ä¸­åšçš„é‚£æ¨£ã€‚

# å‡è¨­ä½ å·²ç¶“åœ¨é€™è£¡é‡å»ºäº† tokenizer è®Šæ•¸ï¼š
import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer

print("--- æ­£åœ¨é‡å»º Tokenizer... ---")
# è­¦å‘Šï¼šå¦‚æœ emotion_data.csv ä¸åœ¨ app.py åŒä¸€è³‡æ–™å¤¾ï¼Œé€™è£¡æœƒå¤±æ•—
df = pd.read_csv('emotion_data.csv', header=None, names=['text', 'emotion'])
df['tokens'] = df['text'].apply(lambda x: list(jieba.cut(x, cut_all=False)))
texts = [" ".join(tokens) for tokens in df['tokens']]
tokenizer = Tokenizer(num_words=5000, oov_token="<unk>") 
tokenizer.fit_on_texts(texts)

print("'tokenizer' å·²æˆåŠŸå¾ emotion_data.csv é‡å»ºï¼")

# --- 1. æ ¸å¿ƒé‚è¼¯å‡½å¼ (è¤‡è£½è‡ªä½ çš„ Notebook) ---

# 1.1 LSTM åˆ¤æ–·æƒ…ç·’
def predict_emotion(text_input, model, tokenizer, max_len, emotion_classes):
    # é€™è£¡å‡è¨­ tokenizer å·²ç¶“ä½œç‚ºå…¨å±€è®Šæ•¸å®šç¾©
    tokens = list(jieba.cut(text_input, cut_all=False))
    text_processed = [" ".join(tokens)]
    sequence = tokenizer.texts_to_sequences(text_processed)
    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')
    predictions = model.predict(padded_sequence, verbose=0)
    
    predicted_class = np.argmax(predictions, axis=1)[0]
    predicted_emotion = emotion_classes[predicted_class]
    confidence = predictions[0][predicted_class]
    
    return predicted_emotion, confidence

# 1.2 æ¨è–¦é‚è¼¯ (ä½ å®šç¨¿çš„è¡¨æ ¼)
recommendation_logic = {
    'å–œæ‚…': {'type': 'ç¤¾äº¤å‹èˆˆè¶£ / åˆ†äº«', 'reason': 'ä½ å¿ƒæƒ…è¶…æ£’ï¼æ˜¯æ™‚å€™è·Ÿæœ‹å‹åˆ†äº«é€™ä»½å–œæ‚…ï¼Œèˆ‰è¾¦ä¸€å ´ç¾é£Ÿèšæœƒå§ï¼'},
    'æ‚²å‚·': {'type': 'å‰µé€ å‹ / ç™¼æ´©å‹èˆˆè¶£', 'reason': 'ä½ ç¾åœ¨çš„æƒ…ç·’éœ€è¦å‡ºå£ï¼Œä¸å¦‚æ‹¿èµ·ç´™ç­†ç•«ä¸‹ä½ çš„å¿ƒæƒ…ï¼Œæˆ–å¯«é»æ±è¥¿å§ï¼è®“å‰µä½œæ›¿ä½ èªªå‡ºé‚£äº›èªªä¸å‡ºå£çš„æ„Ÿå—ã€‚'},
    'æ†¤æ€’': {'type': 'ç ´å£å‹ / é«˜å¼·åº¦å‹èˆˆè¶£', 'reason': 'ç«æ°£æ»¿æ»¿ï¼Ÿæ‰¾å€‹å®‰å…¨çš„æ–¹å¼æŠŠåŠ›é‡é‡‹æ”¾å‡ºå»ï¼å»åšé«˜å¼·åº¦é‹å‹•ã€æ‰“æ²™åŒ…ï¼Œè®“æƒ…ç·’åœ¨é‹å‹•è£¡è¢«ç‡ƒç‡’æ‰ã€‚'},
    'ç„¦æ…®': {'type': 'å°ˆæ³¨å‹ / é‡è¤‡å‹èˆˆè¶£', 'reason': 'å¿ƒæœ‰é»äº‚ï¼Ÿè©¦è©¦éœ€è¦é‡è¤‡å‹•ä½œçš„å°æ´»å‹•å§ï¼åƒæ˜¯æ‹¼åœ–ã€æ‘ºç´™æˆ–åˆ†é¡å°ç‰©ï¼Œå°ˆæ³¨æ„Ÿæœƒè®“ç„¦æ…®æ…¢æ…¢å®‰éœä¸‹ä¾†ã€‚'},
    'å¹³éœ': {'type': 'æ¢ç´¢å‹ / æ”¾é¬†å‹èˆˆè¶£', 'reason': 'ä½ ç¾åœ¨æ•£ç™¼è‘—ç©©å®šçš„èƒ½é‡ï½ä¸å¦¨æ•£æ­¥æ¢ç´¢å‘¨é­ï¼Œæˆ–è½é»è¼•éŸ³æ¨‚ï¼Œäº«å—é€™ä»½é›£å¾—çš„å¹³å’Œã€‚'},
    'å­æƒ¡': {'type': 'æ¸…ç†å‹ / è½‰æ›å‹èˆˆè¶£', 'reason': 'æœ‰ç¨®è¢«æ±è¥¿æƒ¹æ¯›çš„æ„Ÿè¦ºï¼Ÿé‚£æ­£æ˜¯æ•´ç†çš„å¥½æ™‚æ©Ÿï¼æ¸…æ‰ç…©äººçš„é›œç‰©ï¼Œè®“ç’°å¢ƒå’Œå¿ƒæƒ…ä¸€èµ·ç…¥ç„¶ä¸€æ–°ã€‚'},
    'æœŸå¾…': {'type': 'è¨ˆåŠƒå‹ / å‰µä½œå‹èˆˆè¶£', 'reason': 'ä½ èˆˆå¥®å¾—åƒæº–å‚™é–‹å•Ÿæ–°é—œå¡ï¼è¶é€™è‚¡èƒ½é‡ï¼ŒæŠŠä½ çš„è¨ˆç•«å…·é«”åŒ–å§ï½åˆ—æ¸…å–®ã€æ‰¾éˆæ„Ÿã€åšè…¦åŠ›æ¿€ç›ªï¼Œè®“æœŸå¾…è®Šæˆè¡Œå‹•ã€‚'},
    'é©šè¨': {'type': 'æ¢ç´¢å‹ / èªçŸ¥å‹èˆˆè¶£', 'reason': 'å“‡ï¼ä½ çš„å¥½å¥‡å¿ƒè¢«é»äº®äº†ï¼ä¸å¦‚è¶å‹¢å¤šäº†è§£ä¸€ä¸‹å‰›å‰›è®“ä½ é©šè¨çš„äº‹ï¼ŒæŸ¥è³‡æ–™ã€çœ‹å½±ç‰‡ï¼Œè®“é©šè¨è®Šæˆæœ‰è¶£çš„æ–°ç™¼ç¾ã€‚'}
}

# 1.3 ç”Ÿæˆå¼æ¨è–¦å‡½å¼ (Gemini çµ„ç¹”èªè¨€)
def generate_conversational_recommendation(text_input, model, logic, client):
    # with graph.as_default(): # é©ç”¨æ–¼èˆŠç‰ˆ TensorFlow å¤šåŸ·è¡Œç·’
    predicted_emotion, confidence = predict_emotion(text_input, model, tokenizer, max_len, emotion_classes)
    
    recommendation_info = logic.get(predicted_emotion, {'type': 'ç„¡æ­¤é¡åˆ¥', 'reason': 'è«‹ä¼‘æ¯'})
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹æº«æš–ã€å°ˆæ¥­ã€å¹½é»˜çš„ AI å¿ƒç†æ•™ç·´ã€‚ä½ å°é‡æ©Ÿã€é›»å‰ä»–ã€ç¾é£Ÿæ¢ç´¢ç­‰å¤šç¨®èˆˆè¶£æœ‰æ·±åˆ»è¦‹è§£ã€‚
    ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šä»¥ä¸‹è³‡è¨Šï¼Œç”¨è¦ªåˆ‡çš„å£èªåŒ–èªæ°£ï¼Œé¼“å‹µç”¨æˆ¶ä¸¦çµ¦äºˆä¸€å€‹å…·é«”çš„ã€èˆ‡ä»–å€‘èˆˆè¶£ï¼ˆé‡æ©Ÿã€é›»å‰ä»–ã€ç¾é£Ÿï¼‰ç›¸é—œçš„è¡Œå‹•å»ºè­°ã€‚
    è«‹é¿å…ä½¿ç”¨å›ºå®šçš„æ¨¡æ¿ã€‚

    ç”¨æˆ¶çš„åŸå§‹è¼¸å…¥æ˜¯: "{text_input}"
    ç³»çµ±åˆ¤æ–·çš„æƒ…ç·’æ˜¯: {predicted_emotion}
    ç³»çµ±å»ºè­°çš„æ´»å‹•é¡å‹æ˜¯: {recommendation_info['type']}
    ç³»çµ±å»ºè­°çš„å›ºå®šç†ç”±æ˜¯: {recommendation_info['reason']}
    
    è«‹æ ¹æ“šé€™äº›è³‡è¨Šï¼Œç”Ÿæˆä¸€æ®µæµæš¢çš„é¼“å‹µå’Œæ¨è–¦èªã€‚
    """
    
    response = client.models.generate_content(
        model='gemini-2.5-pro',
        contents=prompt
    )
    
    return {
        'ai_response': response.text,
        'predicted_emotion': predicted_emotion,
        'confidence': f"{confidence*100:.2f}%"
    }


# --- 2. Flask API å®šç¾© ---
app = Flask(__name__)

@app.route('/api/recommend', methods=['POST'])
def recommend():
    try:
        # æ¥æ”¶å‰ç«¯ POST éä¾†çš„ JSON è³‡æ–™
        data = request.get_json()
        user_text = data.get('text', '')
        
        if not user_text:
            return jsonify({"error": "Missing 'text' in request body"}), 400

        # å‘¼å«æ ¸å¿ƒæ¨è–¦é‚è¼¯
        result = generate_conversational_recommendation(user_text, final_model, recommendation_logic, client)
        
        # è¿”å› JSON æ ¼å¼çš„çµæœçµ¦å‰ç«¯
        return jsonify(result)

    except Exception as e:
        print(f"API è™•ç†éŒ¯èª¤: {e}")
        return jsonify({"error": "Internal Server Error", "message": str(e)}), 500

# --- 3. æœå‹™å•Ÿå‹• ---
if __name__ == '__main__':
    # æœå‹™å°‡åœ¨æœ¬åœ° 5000 åŸ å£é‹è¡Œ
    print("Flask æœå‹™å•Ÿå‹•ä¸­...")
    app.run(host='0.0.0.0', port=5000)