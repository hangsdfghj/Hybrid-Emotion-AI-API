import os
# é—œéµå„ªåŒ–ï¼šæŠ‘åˆ¶ TensorFlow çš„å•Ÿå‹•æ—¥èªŒå’Œè­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
os.environ["CUDA_VISIBLE_DEVICES"] = "-1" # ç¢ºä¿ä½¿ç”¨ CPU

import numpy as np
import jieba
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from google import genai
# ğŸš¨ ä¿®æ­£ï¼šå°å…¥ APIError ä»¥è™•ç†æ‰€æœ‰ Gemini API éŒ¯èª¤
from google.genai.errors import APIError
from flask import Flask, request, jsonify
from flask_cors import CORS

# --- 0. å…¨åŸŸè®Šæ•¸èˆ‡æ¨¡å‹è¼‰å…¥ (åƒ…åœ¨æœå‹™å•Ÿå‹•æ™‚åŸ·è¡Œä¸€æ¬¡) ---

client = genai.Client()

emotion_classes = np.array(['å­æƒ¡', 'å–œæ‚…', 'å¹³éœ', 'æ‚²å‚·', 'æ†¤æ€’', 'æœŸå¾…', 'ç„¦æ…®', 'é©šè¨']) 
max_len = 16 

# ğŸš¨ æ¨¡å‹è¼‰å…¥æ—è·¯ (Mock Model) - ä¿æŒä¸è®Šï¼Œä»¥ç¢ºä¿å•Ÿå‹•é€Ÿåº¦
# æˆ‘å€‘ä½¿ç”¨æ¨¡æ“¬æ¨¡å‹ä¾†æ¸¬è©¦ API Key æ˜¯å¦æ­£å¸¸
class MockEmotionModel:
    """ç”¨æ–¼å–ä»£ TensorFlow æ¨¡å‹ï¼Œè®“æœå‹™å¿«é€Ÿå•Ÿå‹•ä¸¦æ¨¡æ“¬ä¸€å€‹é æ¸¬çµæœ (ä¾‹å¦‚: ç„¦æ…®)ã€‚"""
    def predict(self, padded_sequence, verbose=0):
        # æ¨¡æ“¬ä¸€å€‹ 'ç„¦æ…®' (ç´¢å¼• 6) çš„é«˜ä¿¡å¿ƒåº¦çµæœ
        return np.array([[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.65, 0.05]]) 

final_model = MockEmotionModel() 
print("æ¨¡å‹è¼‰å…¥å·²æ—è·¯ã€‚æ­£åœ¨ä½¿ç”¨æ¨¡æ“¬æ¨¡å‹é€²è¡Œå•Ÿå‹•æ¸¬è©¦ã€‚")


# Tokenizer é‡å»ºé‚è¼¯
import pandas as pd
from tensorflow.keras.preprocessing.text import Tokenizer

print("--- æ­£åœ¨é‡å»º Tokenizer... ---")
try:
    df = pd.read_csv('emotion_data.csv', header=None, names=['text', 'emotion'])
    df['tokens'] = df['text'].apply(lambda x: list(jieba.cut(x, cut_all=False)))
    texts = [" ".join(tokens) for tokens in df['tokens']]
    tokenizer = Tokenizer(num_words=5000, oov_token="<unk>") 
    tokenizer.fit_on_texts(texts)
    print("'tokenizer' å·²æˆåŠŸå¾ emotion_data.csv é‡å»ºï¼")
except FileNotFoundError:
    print("FATAL ERROR: ç„¡æ³•æ‰¾åˆ° 'emotion_data.csv' æª”æ¡ˆã€‚")

# --- 1. æ ¸å¿ƒé‚è¼¯å‡½å¼ (ç¶­æŒä¸è®Š) ---

def predict_emotion(text_input, model, tokenizer, max_len, emotion_classes):
    tokens = list(jieba.cut(text_input, cut_all=False))
    text_processed = [" ".join(tokens)]
    sequence = tokenizer.texts_to_sequences(text_processed)
    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')
    predictions = model.predict(padded_sequence, verbose=0)
    
    predicted_class = np.argmax(predictions, axis=1)[0]
    predicted_emotion = emotion_classes[predicted_class]
    confidence = predictions[0][predicted_class]
    
    return predicted_emotion, confidence

recommendation_logic = {
    'å–œæ‚…': {'type': 'ç¤¾äº¤å‹èˆˆè¶£ / åˆ†äº«', 'reason': 'ä½ å¿ƒæƒ…è¶…æ£’ï¼æ˜¯æ™‚å€™è·Ÿæœ‹å‹åˆ†äº«é€™ä»½å–œæ‚…ï¼Œèˆ‰è¾¦ä¸€å ´ç¾é£Ÿèšæœƒå§ï¼'},
    'æ‚²å‚·': {'type': 'å‰µé€ å‹ / ç™¼æ´©å‹èˆˆè¶£', 'reason': 'ä½ ç¾åœ¨çš„æƒ…ç·’éœ€è¦å‡ºå£ï¼Œä¸å¦‚æ‹¿èµ·ç´™ç­†ç•«ä¸‹ä½ çš„å¿ƒæƒ…ï¼Œæˆ–å¯«é»æ±è¥¿å§ï¼è®“å‰µä½œæ›¿ä½ èªªå‡ºé‚£äº›èªªä¸å‡ºå£çš„æ„Ÿå—ã€‚'},
    'æ†¤æ€’': {'type': 'ç ´å£å‹ / é«˜å¼·åº¦å‹èˆˆè¶£', 'reason': 'ç«æ°£æ»¿æ»¿ï¼Ÿæ‰¾å€‹å®‰å…¨çš„æ–¹å¼æŠŠåŠ›é‡é‡‹æ”¾å‡ºå»ï¼å»åšé«˜å¼·åº¦é‹å‹•ã€æ‰“æ²™åŒ…ï¼Œè®“æƒ…ç·’åœ¨é‹å‹•è£¡è¢«ç‡ƒç‡’æ‰ã€‚'},
    'ç„¦æ…®': {'type': 'å°ˆæ³¨å‹ / é‡è¤‡å‹èˆˆè¶£', 'reason': 'å¿ƒæœ‰é»äº‚ï¼Ÿè©¦è©¦éœ€è¦é‡è¤‡å‹•ä½œçš„å°æ´»å‹•å§ï¼åƒæ˜¯æ‹¼åœ–ã€æ‘ºç´™æˆ–åˆ†é¡å°ç‰©ï¼Œå°ˆæ³¨æ„Ÿæœƒè®“ç„¦æ…®æ…¢æ…¢å®‰éœä¸‹ä¾†ã€‚'},
    'å¹³éœ': {'type': 'æ¢ç´¢å‹ / æ”¾é¬†å‹èˆˆè¶£', 'reason': 'ä½ ç¾åœ¨æ•£ç™¼è‘—ç©©å®šçš„èƒ½é‡ï½ä¸å¦¨æ•£æ­¥æ¢ç´¢å‘¨é­ï¼Œæˆ–è½é»è¼•éŸ³æ¨‚ï¼Œäº«å—é€™ä»½é›£å¾—çš„å¹³å’Œã€‚'},
    'å­æƒ¡': {'type': 'æ¸…ç†å‹ / è½‰æ›å‹èˆˆè¶£', 'reason': 'æœ‰ç¨®è¢«æ±è¥¿æƒ¹æ¯›çš„æ„Ÿè¦ºï¼Ÿé‚£æ­£æ˜¯æ•´ç†çš„å¥½æ™‚æ©Ÿï¼æ¸…æ‰ç…©äººçš„é›œç‰©ï¼Œè®“ç’°å¢ƒå’Œå¿ƒæƒ…ä¸€èµ·ç…¥ç„¶ä¸€æ–°ã€‚'},
    'æœŸå¾…': {'type': 'è¨ˆåŠƒå‹ / å‰µä½œå‹èˆˆè¶£', 'reason': 'ä½ èˆˆå¥®å¾—åƒæº–å‚™é–‹å•Ÿæ–°é—œå¡ï¼è¶é€™è‚¡èƒ½é‡ï¼ŒæŠŠä½ çš„è¨ˆç•«å…·é«”åŒ–å§ï½åˆ—æ¸…å–®ã€æ‰¾éˆæ„Ÿã€åšè…¦åŠ›æ¿€ç›ªï¼Œè®“æœŸå¾…è®Šæˆè¡Œå‹•ã€‚'},
    'é©šè¨': {'type': 'æ¢ç´¢å‹ / èªçŸ¥å‹èˆˆè¶£', 'reason': 'å“‡ï¼ä½ çš„å¥½å¥‡å¿ƒè¢«é»äº®äº†ï¼ä¸å¦‚è¶å‹¢å¤šäº†è§£ä¸€ä¸‹å‰›å‰›è®“ä½ é©šè¨çš„äº‹ï¼ŒæŸ¥è³‡æ–™ã€çœ‹å½±ç‰‡ï¼Œè®“é©šè¨è®Šæˆæœ‰è¶£çš„æ–°ç™¼ç¾ã€‚'}
}

def generate_conversational_recommendation(text_input, model, logic, client):
    """çµåˆæƒ…ç·’é æ¸¬çµæœï¼Œå‘¼å« Gemini ç”Ÿæˆå€‹æ€§åŒ–çš„æ•™ç·´å»ºè­°ã€‚"""
    try:
        predicted_emotion, confidence = predict_emotion(text_input, final_model, tokenizer, max_len, emotion_classes)
    except Exception as e:
        return {
            'ai_response': f"LSTM æ¨¡å‹é æ¸¬å¤±æ•—ï¼š{str(e)}",
            'predicted_emotion': "éŒ¯èª¤",
            'confidence': "0.00%"
        }
    
    recommendation_info = logic.get(predicted_emotion, {'type': 'ç„¡æ­¤é¡åˆ¥', 'reason': 'è«‹ä¼‘æ¯'})
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹æº«æš–ã€å°ˆæ¥­ã€å¹½é»˜çš„ AI å¿ƒç†æ•™ç·´ã€‚ä½ å°é‡æ©Ÿã€é›»å‰ä»–ã€ç¾é£Ÿæ¢ç´¢ç­‰å¤šç¨®èˆˆè¶£æœ‰æ·±åˆ»è¦‹è§£ã€‚
    ... (ç•¥ï¼Œä¿æŒæç¤ºä¸è®Š)
    """
    
    try:
        # å˜—è©¦å‘¼å« Gemini API
        response = client.models.generate_content(
            model='gemini-2.5-pro',
            contents=prompt
        )
        
        return {
            'ai_response': response.text,
            'predicted_emotion': predicted_emotion,
            'confidence': f"{confidence*100:.2f}%"
        }
        
    except APIError as e:
        # ğŸš¨ ä¿®æ­£ï¼šæ•æ‰é€šç”¨çš„ APIError
        error_message = str(e)
        if "Permission denied" in error_message or "Invalid API key" in error_message:
             # å¦‚æœæ˜¯ 403 éŒ¯èª¤ï¼Œæä¾›è¨ºæ–·è¨Šæ¯
             return {
                'ai_response': "Gemini API å‘¼å«å¤±æ•—ï¼šæ¬Šé™é­æ‹’ã€‚è«‹æª¢æŸ¥ Render ä¸Šçš„ GEMINI_API_KEY æ˜¯å¦è¨­å®šæ­£ç¢ºä¸”æœ‰æ•ˆã€‚",
                'predicted_emotion': predicted_emotion,
                'confidence': f"{confidence*100:.2f}%"
            }
        else:
            # è™•ç†å…¶ä»– API éŒ¯èª¤ (å¦‚ Rate limit, 400, 500)
            return {
                'ai_response': f"Gemini API å‘¼å«å¤±æ•—ï¼šç™¼ç”Ÿ API éŒ¯èª¤ {type(e).__name__}ï¼ŒéŒ¯èª¤è¨Šæ¯ï¼š{error_message[:100]}...",
                'predicted_emotion': predicted_emotion,
                'confidence': f"{confidence*100:.2f}%"
            }
    except Exception as e:
        # è™•ç†å…¶ä»–æ‰€æœ‰é API éŒ¯èª¤
        return {
            'ai_response': f"Gemini API å‘¼å«å¤±æ•—ï¼šç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ {type(e).__name__}ï¼Œè«‹æª¢æŸ¥ Render æ—¥èªŒã€‚",
            'predicted_emotion': predicted_emotion,
            'confidence': f"{confidence*100:.2f}%"
        }


# --- 2. Flask API å®šç¾© (ç¶­æŒä¸è®Š) ---
app = Flask(__name__)
CORS(app) 

@app.route('/api/recommend', methods=['POST'])
def recommend():
    try:
        data = request.get_json()
        user_text = data.get('text', '')
        
        if not user_text:
            return jsonify({"error": "Missing 'text' in request body"}), 400

        result = generate_conversational_recommendation(user_text, final_model, recommendation_logic, client)
        
        return jsonify(result)

    except Exception as e:
        print(f"API è™•ç†éŒ¯èª¤: {e}")
        return jsonify({"error": "Internal Server Error", "message": str(e)}), 500
